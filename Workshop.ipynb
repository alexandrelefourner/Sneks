{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 1 : Principes fondamentaux\n",
    "\n",
    "Ce notebook vise à comprendre comme le réseau de neurone fonctionne \"à l'intérieur\".\n",
    "Suivez pas à pas les cellules pour parvenir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lexml.lexmlexercices import * #La librarie est nécessaire pour les tests de vérification\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activate(entry):\n",
    "    #A faire: : Ecrire une fonction, laquelle retourne 1 si le threshold de 1 est passé, sinon 0.\n",
    "    return None\n",
    "\n",
    "\n",
    "test_activation(activate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def or_gate(entry_1, entry_2):\n",
    "    \n",
    "    #A faire: Déterminer le poids des neurons pour que la porte\n",
    "    #       s'active si l'un ou l'autre des neurones envoie un signal de 1.\n",
    "    #Note: N'oubliez pas d'utiliser la fonction d'activation.\n",
    "    \n",
    "    weight_neuron_1 = None\n",
    "    weight_neuron_2 = None\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "test_or_gate(or_gate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def and_gate(entry_1, entry_2):\n",
    "    #A faire: Déterminer le poids des neurons pour que la porte\n",
    "    #      s'active si les 2 neurones envoient un signal de 1.\n",
    "    \n",
    "    weight_neuron_1 = None\n",
    "    weight_neuron_2 = None\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "test_and_gate(and_gate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def xor_gate_pure_neuron(entry_1, entry_2):\n",
    "    #A faire: En vous basant sur votre travail précédent, créez une porte qui s'active\n",
    "    #Quand entry_1 ou entry_2 envoie la valeur de 1, mais ne s'active pas si les 2 sont activés.\n",
    "    \n",
    "    #Astuce : Utilisez les output de and_gate et or_gate comme input d'une troisième couche.\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "test_xor_gate(xor_gate_pure_neuron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L'opération logique NOT\n",
    "\n",
    "Inverser un résultat de 0 à 1 ou de 1 à 0 est une opération très courante.<br>\n",
    "La porte logique la réalisant s'appelle la porte NOT.<br>\n",
    "Créez la dans la cellule qui suit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def not_gate(entry):\n",
    "    #A faire: Considérant le code écrit pour votre fonction Activate(), créez une porte qui:\n",
    "    #Donne 0 si le threshold de 1 est passé.\n",
    "    #Donne 1 dans les autres cas.\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "test_not_gate(not_gate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nand_gate(entry_1, entry_2):\n",
    "    #A faire: Créer une porte qui retourne 1 tout le temps,\n",
    "    #sauf quand les deux neurones d'entrée envoient un signal en même temps.\n",
    "    \n",
    "    #Astuce : Utilisez les fonctions présentées ci-avant\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "test_nand_gate(nand_gate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approche dynamique ou seulement de poids.\n",
    "\n",
    "Dans l'exemple précédent, vous avez vu qu'il était possible de modifier l'activation du neurone pour modifier la porte. Si vous souhaitez qu'un réseau de neurone fonctionne comme cela pour s'entraîner, à savoir modifier la structure de son architecture, nous dirons que vous utilisez une approche __dynamique__.<br>\n",
    "<br>\n",
    "Ce type de stratégie est utilisée dans quelques architectures, telle que les Algorithmes Génétiques.<br>\n",
    "<br>\n",
    "Cependant, le développement de récents algorithmes cherche à éviter ce mode de fonctionnement, principalement pour une efficiacité de calcul. A la place, ceux-ci cherchent à garder une architecture figée, où seuls les poids des neurones changent.<br>\n",
    "<br>\n",
    "Dans l'exemple suivant, cherchez à n'utiliser que le poids des neurones pour créer la porte, __n'utilisez cependant que l'activation activate()__.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nand_gate_pure_neuron(entry_1, entry_2):\n",
    "    #A faire: Recréez la porte nand, mais sans utiliser la fonction not_gate() pour l'activer.\n",
    "    \n",
    "    w_and = None\n",
    "    w_bias = None\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "test_nand_gate(nand_gate_pure_neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nor_gate_pure_neuron(entry_1, entry_2):\n",
    "    #A faire: Sans utiliser la fonction not_gate, créez une porte qui retourne tout le temps 1, \n",
    "    #Sauf quand un neurone est activé.\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "test_nor_gate(nor_gate_pure_neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xnor_gate_pure_neuron(entry_1, entry_2):\n",
    "    #A faire: Sans utiliser la fonction not_gate, créez une porte qui retourne tout le temps 1, \n",
    "    #Sauf quand un unique neurone est activé.\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "test_xnor_gate(xnor_gate_pure_neuron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 2 : Le jeu de BabySneks\n",
    "## Partie A : Installation\n",
    "\n",
    "Nous allons travailler ensemble avec le jeu de Sneks, par nicomon24. Tout devrait être installé et vous allez pouvoir passer directement en partie B. Si vous avez toutefois une erreur, vous pouvez décommenter et reprocéder à l'installation<br>\n",
    "<img src=\"https://raw.githubusercontent.com/nicomon24/Sneks/master/src/babysnek.gif\"></img><br><br>\n",
    "Pour cela, vous devez avoir installé <a href=\"https://github.com/nicomon24/Sneks\">la repository git associée</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!git clone https://github.com/nicomon24/Sneks\n",
    "!pip install -e ./Sneks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vous êtes sur windows, executez la cellule suivante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!move ./Sneks/sneks ./snek\n",
    "!rd /s /q Sneks\n",
    "!move ./snek ./sneks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour linux:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!mv ./Sneks/sneks ./snek\n",
    "!rm -rf gym-snake\n",
    "!mv ./snek ./sneks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie B : Apprivoiser l'environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym #Import gym library from OpenAI\n",
    "import sneks\n",
    "\n",
    "env = gym.make('babysnek-raw-16-v1') #Crée l'environnement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commandes:\n",
    "- <b>env.reset()</b> : Réinitialise un environnement et vous retourne l'observation\n",
    "- <b>env.render()</b> : Affiche une fenêtre avec l'environnement (elle freeze, c'est normal... elle attend les instructions). Doit être appelé pour mettre à jour chaque action.\n",
    "- <b>env.close()</b> : ferme la fenêtre de l'environnement\n",
    "- <b>env.action_space</b> : Vous montre le type d'action attendue par l'environnement (ici, un nombre entre 1 et 4)\n",
    "- <b>env.action_space.sample()</b> : Vous donne une valeur aléatoire à envoyer à l'environnement pour jouer (un nombre entre 1 et 4)\n",
    "- <b>env.step(action)</b> : joue l'action dans l'environnement. Renvoie quatre valeurs:\n",
    "    - observation : la plateforme de jeu, comme pour env.reset\n",
    "    - reward : la récompense reçue par votre serpent\n",
    "    - done : True si la partie est terminée. False si elle dure toujours\n",
    "    - infos : Inutile ici.\n",
    "    \n",
    "### Observations:\n",
    "- 0 : Case vide\n",
    "- 64 : la pomme\n",
    "- 255 : un mur\n",
    "- 101 : La tête du serpent\n",
    "- 100 : le corps du serpent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Todo: Créez une boucle jusqu'à ce que la partie se termine en affichant le serpent qui se déplace à chaque étape.\n",
    "#Vous devez avoir fait un reset de l'environnement avant votre boucle.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A présent, vous allez devoir utiliser la librairie Numpy pour manipuler le tableau. Votre objectif est d'amener le serpent au fruit, par un système de conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #On importe la librairie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple de commandes numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(10) #génère une suite de 0 à 9 inclus. La suite est dans un tableau à 1 dimension, appelé vecteur.\n",
    "a #équivalent de print(a) si c'est sur la dernière ligne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([2, 18, 21, 7]) #Transforme une liste en vecteur numpy.\n",
    "a[0] #Sélectionne la première entrée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([2, 18, 21, 7])\n",
    "print(a[-1],\"|\", a[-2]) #Prend la dernière entrée de mon vecteur, puis l'avant-dernière"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((3,4)) #Crée un tableau de 3 lignes et 4 colonnes, toutes remplies de 0\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ones((3,4)) #Crée un tableau de 3 lignes et 4 colonnes, toutes remplies de 1\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(10)\n",
    "b = np.reshape(a, (2,5)) #transforme le vecteur de forme (10,) en tableau de la forme (2,5) (appelé matrice)\n",
    "#2 lignes et 5 colonnes\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(10)\n",
    "b = np.reshape(a, (2,-1)) # -1 est un joker, qui signifie \"remplit avec ce qu'il manque\"\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[0] #Sélectionne la première ligne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[0,2] #Sélectionne la première ligne, puis la troisième colonne (première colonne c'est 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[:,2] #Sélectionne toutes les lignes, puis la troisième colonne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[0,1:4] #Sélectionne la première ligne, puis les colonnes de 1 à 4 exclus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(10)\n",
    "b = a / 2 #Divise tous les éléments du vecteur par 2\n",
    "c = a * 2 #Multiplie tous les éléments du vecteur par 2\n",
    "print(a)\n",
    "print(\"========\")\n",
    "print(b)\n",
    "print(\"========\")\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(5)\n",
    "b = np.where(a == 3, 1, 0)#Applique un masque de condition. \n",
    "#Le premier paramètre est la condition.\n",
    "#Si True, modifie la valeur au deuxième paramètre.\n",
    "#Si False, modifie la valeur au troisième paramètre.\n",
    "print(a)\n",
    "print(\"========\")\n",
    "print(b) #3 est remplacé par 1, le reste par 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(5)\n",
    "b = np.where(a == 3, 1, a)#Il est possible de conserver une valeur précédente en réutilisant la variable.\n",
    "print(a)\n",
    "print(\"========\")\n",
    "print(b) #Le 3 est remplacé par 1, mais le reste est conservé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(5)\n",
    "a[2] = 21\n",
    "a[3] = -10\n",
    "\n",
    "print(\"Le minimum est\", a.min(), \"à la position\", np.argmin(a)) #Minimum et position du minimum\n",
    "print(\"Le maximum est\", a.max(), \"à la position\", np.argmax(a)) #Maximum et position du maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(10)\n",
    "b = [a * i for i in range(3)] #Crée une liste de vecteurs\n",
    "print(b)\n",
    "print(\"========\")\n",
    "c = np.vstack(b) #Empile les vecteurs.\n",
    "print(c)\n",
    "print(\"========\")\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(10)\n",
    "b = [a * i for i in range(3)]\n",
    "c = np.vstack(b)\n",
    "print(c)\n",
    "print(\"========\")\n",
    "d = np.roll(c, 1, 0) #Décale de 1 sur l'axis 0 (les lignes)\n",
    "print(d)\n",
    "print(\"========\")\n",
    "print(\"========\")\n",
    "print(c)\n",
    "print(\"========\")\n",
    "d = np.roll(c, 1, 1) #Décale de 1 sur l'axis 1 (les colonnes)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pratique avec Numpy\n",
    "Un peu de pratique désormais : Remplir la fonction pour trouver la position de la pomme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_apple_position(observation):\n",
    "    #TODO: donner la position x (ligne) et y (colonne) de la pomme.\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "test_check_get_apple_position_function(env, get_apple_position)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Une version manuelle\n",
    "A l'aide de numpy, générez une fonction pour dire au serpent par où aller pour rejoindre la pomme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_the_snake(observation):\n",
    "    \n",
    "    #Retourne 0 pour monter\n",
    "    #Retourne 1 pour aller à droite.\n",
    "    #Retourne 2 pour descendre\n",
    "    #Retourne 3 pour aller à gauche\n",
    "    \n",
    "    return movement\n",
    "\n",
    "#Teste de l'efficacité de notre fonction.\n",
    "test_check_move_the_snake(env, move_the_snake, simulations=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie C : Intelligence supervisée\n",
    "\n",
    "Maintenant que nous avons vu comment fonctionne l'environnement, nous allons chercher à entrainer une I.A. pour la résoudre. Pour cela, nous allons charger des parties déjà jouées et utiliser une I.A. pour créer la fonction qui prend en entrée l'état du jeu et qui ressort le mouvement à réaliser en sortie.<br>\n",
    "L'entrainement va se baser sur des parties déjà jouées et nous allons essayer d'enseigner à une I.A. comment apprendre.<br><br>\n",
    "### Sélection de la data\n",
    "Deux choix s'offrent à vous pour la data:<br>\n",
    "- Si vous avez obtenu de bonnes performances avec votre algorithmes, vous pouvez utiliser la fonction generate_samples() qui va jouer un grand nombre de parties pour créer la data.<br>\n",
    "- Si vous préférez, vous pouvez charger les fichiers pré-enregistrés qui ont déjà été réalisés avec le notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_, y_ = generate_samples(env, move_the_snake) #Si vous désirez créer de la data depuis votre fonction.\n",
    "#X_, y_ = np.load(\"X_data.npy\"), np.load(\"Y_data.npy\") #Depuis une base préchargée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Créer une dataset de control\n",
    "Nous allons utiliser <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\">sklearn</a> afin de contrôler l'overfitting du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#On sépare notre dataset en conservant 80% pour l'entrainement, 20% pour le test.\n",
    "X_train, x_test, Y_train, y_test = train_test_split(X_, y_, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilisation de KNN\n",
    "Sklearn <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">intègre déjà l'algorithme KNN</a>. Nous allons donc utiliser un algorithme KNN et examiner ses performances.\n",
    "KNN ne tient cependant pas compte des tableaux et ne manipule que des vecteurs.<br>\n",
    "Nous allons donc devoir \"applatir\" le tableau pour passer de 2 dimensions à 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (-1, 16*16))\n",
    "x_test = np.reshape(x_test, (-1, 16*16))\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois KNN importé, stoquez l'algorithme dans la variable classifier.<br>\n",
    "- <b>KNeighborsClassifier(n_neighbors=k)</b> : Crée l'objet. Choisissez la valeur k pour déterminer le nombre de voisins examinés.\n",
    "- <b>classifier.fit(X, Y)</b> : Permet d'informer le classifier de la localisation des points connus et de leur classe.\n",
    "- <b>classifier.predict(x)</b> : Retourne un vecteur contenant les classes estimées par le classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=3) #On initialize une I.A. KNN, avec k=3\n",
    "#TODO: entraîner l'I.A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Désormais, nous allons vérifier comment l'entrainement s'est déroulé.<br>\n",
    "Pour cela, nous allons regarder les performances de l'I.A. sur une dataset qu'elle n'a pas vue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_predicted = #Todo : Prédire le x_test\n",
    "plot_confusion_matrix(y_test, x_predicted, classes=np.array([\"Haut\", \"Droite\", \"Bas\", \"Gauche\"]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans l'idéal, nous devrions obtenir une diagonale sans autre parasitage. Voyons désormais les performances de KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_knn(observation):\n",
    "    #Todo : Adaptez la taille de l'observation et retourner le résultat.\n",
    "    #Attention, le classifier est fait pour normalement analyser plusieurs éléments en même temps.\n",
    "    \n",
    "    return movement_selected\n",
    "\n",
    "test_check_move_the_snake(env, use_knn, simulations=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le résultat n'est pas exceptionnel... Nous pouvons surement chercher à améliorer cela.<br>\n",
    "Si vous avez fini en avance, n'hésitez pas à modifier la valeur de k pour voir ce qui se passe si vous prenez plus (ou moins) d'éléments pour prendre une décision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_observation(observation):\n",
    "    #TODO : Normaliser les valeurs\n",
    "    #=====> Nous allons préférer avoir des valeurs comprises entre 0 et 1.\n",
    "    #=====> Dans l'idéal, les informations doivent ressortir\n",
    "    \n",
    "    #TODO : Réduire les dimensions\n",
    "    #Ne conserver que les informations importantes de l'environnement.\n",
    "    \n",
    "    return observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On met à jour notre dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (-1, 16,16))\n",
    "x_test = np.reshape(x_test, (-1, 16,16))\n",
    "\n",
    "\n",
    "X_train_updated = [change_observation(x) for x in X_train]\n",
    "x_test_updated = [change_observation(x) for x in x_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis on réentraine le classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Todo : Réentrainer la variable classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_predicted = #prédire le nouveau format\n",
    "plot_confusion_matrix(y_test, x_predicted, classes=np.array([\"Haut\", \"Droite\", \"Bas\", \"Gauche\"]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans l'idéal, vous devriez obtenir une meilleure répartition des résultats sur la matrice ci-avant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_knn(observation):\n",
    "    #Todo : adaptez au classifier\n",
    "\n",
    "test_check_move_the_snake(env, use_knn, simulations=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie D : Votre premier Réseau de Neurones.\n",
    "\n",
    "Pour ce workshop, nous allons utiliser <a href=\"https://pytorch.org/\">PyTorch</a>. Il s'agit d'une librairie développée par Facebook qui va nous aider à ne pas tout avoir à recoder de A à Z.<br>\n",
    "Elle a le bénéfice de coller de près au fonctionnement de Numpy, ainsi que de permettre la réalisation d'I.A. complexes en peu de lignes de code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch #Importe la librairie nécessaire\n",
    "\n",
    "import torch.nn as nn #Importe la section de la librairie spécifique aux réseaux de neurones.\n",
    "import torch.nn.functional as F #Importe une batterie de fonction (notamment pour les activations.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prise en main de PyTorch\n",
    "\n",
    "Sous PyTorch, un réseau de neurones fonctionne sous la forme d'un objet. Vous pouvez voir ci-après le format standard d'un code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        #Définit la structure du réseau de neurone.\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Utilise le réseau pour transformer la data en prédiction.\n",
    "        return x\n",
    "\n",
    "\n",
    "net = NeuralNetwork() #Crée l'objet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une couche de neurones intégralement connectés à la précédente (dense) est appelée par nn.Linear()\n",
    "- Le premier paramètre constitue la taille d'entrée. Combien de neurones y a-t-il en amont ?\n",
    "- La deuxième couche correspond à la taille de sortie. Combien de neurones y a-t-il dans cette couche ?\n",
    "\n",
    "L'exemple suivant contient 3 couches de neurones. Une couche d'entrée de 5 neurones, une couche \"hidden\" de 3 neurones, une sortie de 2 neurones.\n",
    "\n",
    "<img src=\"img/réseau.jpg\"><br><br>\n",
    "\n",
    "Cela correspondrait au modèle suivant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        \n",
    "        self.hidden_layer = nn.Linear(5, 3) #5 entrées et 3 sorties\n",
    "        self.output_layer = nn.Linear(3, 2) #3 entrées et 2 sortie\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.hidden_layer(x) #On fait passer l'information dans la première couche.\n",
    "        x = F.relu(x) #On active les neurones\n",
    "        \n",
    "        x = self.output_layer(x) #On fait passer l'information modifiée vers la couche de sortie.\n",
    "        x = F.log_softmax(x) #On active la sortie.\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "net = NeuralNetwork() #Crée l'objet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour entrainer votre réseau, vous allez devoir calculer les prédictions du réseau, puis un gradient d'erreur.<br>\n",
    "Le gradient est heureusement pris en charge par PyTorch.<br><br>\n",
    "\n",
    "La data doit cependant être manipulée pour arriver sous la bonne forme au réseau. Cela signifie convertir la data sous forme de tenseur, ainsi que Nos labels qui sont soignés.. Les fonctions ont été importées tout au début du notebook..<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_updated = np.array(X_train_updated)\n",
    "x_test_updated = np.array(x_test_updated)\n",
    "\n",
    "\n",
    "X_train_updated = torch.from_numpy(X_train_updated) #Conversion de la matrice en tenseur.\n",
    "X_train_updated = X_train_updated.float() #Le format aussi est important, notamment pour identifier les zones de stoquaged de l'info.\n",
    "\n",
    "Y_train_tensor = torch.from_numpy(Y_train) #Conversion de la matrice en tenseur.\n",
    "Y_train_tensor = Y_train_tensor.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        \n",
    "        #Todo : paramétrez la structure de votre réseau.\n",
    "    def forward(self, x):\n",
    "        \n",
    "        #TODO : écrire le processus d'inférence\n",
    "        #(n'oubliez les fonctions d'activations)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "net = NeuralNetwork() #Crée l'objet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.adam import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrainement du réseau\n",
    "\n",
    "Pour entrainer votre réseau de neurones, il va vous falloir plusieurs éléments:\n",
    "- Un générateur de batch. Vous n'allez pas pouvoir analyser toute votre data d'un coup. La plupart du temps, vous devez décmoposer vos images pour en montrer un petit nombre à chaque fois au réseau. De là, vous pouvez chercher à construire l'erreur. J'ai déjà pré-programmé une fonction pour ça, cf la case suivante.\n",
    "- Réaliser une prédiction avec le réseau. La procédure est très simple : <b>net(tensor)</b> vous retournera _un tenseur_ en guise de réponse.\n",
    "- Un nombre \"d'epochs\". Il s'agit du nombre de fois que votre I.A. verra la data. On va passer par une boucle for\n",
    "- Un optimiseur. C'est l'outil qui va adapter les poids d'après les gradiens et qui va chercher à progressivement descendre la pente d'erreur. Il en existe un grand nombre, avec leurs avantages et leurs inconvénients. Les deux plus populaires sont SGD et Adam. Comme vous le verrez dans la cellule qui suit, je vous propose d'utiliser Adam dans ce workshop.\n",
    "    - Un optimiseur prend 2 paramètres : Le première, c'est les paramètres du réseau de neurone (pour qu'il connaisse son architecture). PyTorch prend très bien cela en compte et tous les layers identifiés par self vont être aisément accessible. Il suffit d'utiliser <b>net.parameters()</b> pour récupérer les paramètres du réseau.\n",
    "    - L'optimiseur prend en second paramètre un \"Learning Rate\". Il décrit à quelle vitesse vous souhaitez descendre la pente du gradient. Si vous en prenez un trop petit, votre réseau peut mettre plusieurs années à apprendre. Si vous en choisissez un trop grand, votre réseau risque de vouloir aller trop vite et de ne rien apprendre non plus. Il s'agit d'une valeur à chercher de façon empirique. Je vous propose de démarrer avec lr=1e-3\n",
    "    - Avant de faire les nouvelles prédictions pour un calcul d'erreur, il faut réinitialiser les gradients en mémoire. pour cela, appelez la fonction <b>.zero_grad()</b> sur votre optimiseur.\n",
    "    - Une fois que les gradients ont été calculés (j'explique juste après), il vous faut impacter le réseau de neurone. On le fait notamment par optimizer<b>.step()</b>\n",
    "- Une fonction d'erreur, qui va permettre de construire un gradient. Dans notre cas, nous allons utiliser la fonction de crossentropy, avec l'objet . Elle est très bien adaptée aux problèmes de classification comme celui-ci et prend 2 paramètres : les prédictions du réseau face aux réponses attendues. \n",
    "    - Créez l'objet <b>F.nll_loss()</b>. Les deux paramètres comparés seront les prédictions du réseau et vos labels.\n",
    "    - Vous pouvez accéder à l'erreur calculée en appelant <b>loss.item()</b> derrière votre erreur.\n",
    "    - Pour calculer les gradients, vous devez utiliser <b>.backward()</b>\n",
    "        - Tous les gradiens seront ainsi automatiquement calculés d'après l'erreur.\n",
    "        - Il suffira d'effectuer un pas avec l'optimizer.\n",
    "- Si vous souhaitez faire une prédiction sans affecter le poids des neurones (pour tester votre réseau contre l'overfitting), utilisez un <b>with torch.no_grad():</b>\n",
    "- Je vous recommande aussi d'enregistrer l'erreur du réseau et de l'afficher sous forme de graphique ensuite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in generate_batch(X_train, Y_train, batch_size=32):\n",
    "    pass\n",
    "    #Générateur qui va découper votre batch en morceaux de taille batch_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = #Outil qui va chercher comment descendre la pente\n",
    "\n",
    "epochs = 20 #Nombre de fois que la data sera analysée.\n",
    "losses = [] #Utilisée pour afficher la courbe d'erreur à la fin.\n",
    "\n",
    "for _ in tqdm(range(epochs)):\n",
    "    ##TODO: Entrainer le réseau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On regarde les résultats avec notre réseau de neurones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_neuralnet(observation):\n",
    "    observation = change_observation(observation) #On converti sur notre format d'image.\n",
    "    \n",
    "    observation = torch.from_numpy(observation).float() #On génère le tenseur.\n",
    "    \n",
    "    prediction = net(observation) #On génère une prédiction.\n",
    "    prediction = prediction.detach().numpy() #On transfert en array numpy\n",
    "    prediction = prediction.argmax() #On sélectionne le neurone avec le signal le plus élevé.\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "test_check_move_the_snake(env, use_neuralnet, simulations=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sans extraction de features manuelles\n",
    "\n",
    "Vous devriez normalement avoir un résultat similaire à ce que vous aviez obtenu avec l'algorithme KNN. Essayons désormais de voir les résultats sans extraction des features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        \n",
    "        self.entry_layer = nn.Linear(16*16, 64)\n",
    "        #TODO\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.entry_layer(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        #TODO\n",
    "        \n",
    "        \n",
    "        x = F.log_softmax(x) #On active la sortie.\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "net = NeuralNetwork() #Crée l'objet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_updated = np.reshape(X_train, (-1, 16*16))\n",
    "X_train_updated = torch.from_numpy(X_train_updated) #Conversion de la matrice en tenseur.\n",
    "X_train_updated = X_train_updated.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: entraîner le réseau\n",
    "optimizer = #Outil qui va chercher comment descendre la pente\n",
    "\n",
    "epochs = 20 #Nombre de fois que la data sera analysée.\n",
    "losses = [] #Utilisée pour afficher la courbe d'erreur à la fin.\n",
    "\n",
    "for _ in tqdm(range(epochs)):\n",
    "    ##TODO: Entrainer le réseau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysons les résultats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_neuralnet(observation):\n",
    "    observation = np.reshape(observation, -1)\n",
    "    \n",
    "    observation = torch.from_numpy(observation).float() #On génère le tenseur.\n",
    "    prediction = net(observation) #On génère une prédiction.\n",
    "    prediction = prediction.detach().numpy() #On transfert en array numpy\n",
    "    prediction = prediction.argmax() #On sélectionne le neurone avec le signal le plus élevé.\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "test_check_move_the_snake(env, use_neuralnet, simulations=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passage aux convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(8, 8, kernel_size=3)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.hidden_dense = nn.Linear(1152, 32) #3 entrées et 2 sortie\n",
    "        self.output_layer = nn.Linear(32, 4) #3 entrées et 2 sortie\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv2(x) \n",
    "        x = F.relu(x)\n",
    "        x = self.conv2_drop(x) #On affecte un dropout pour limiter l'overfitting.\n",
    "        \n",
    "        \n",
    "        x = x.view(-1, 1152) #Un équivalent du reshape, mais pour PyTorch\n",
    "        \n",
    "        x = self.hidden_dense(x)\n",
    "        x = F.relu(x) #On active les neurones\n",
    "        x = self.output_layer(x) #On fait passer l'information modifiée vers la couche de sortie.\n",
    "        x = F.log_softmax(x, dim=1) #On active la sortie.\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "net = NeuralNetwork() #Crée l'objet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.from_numpy(X_train) #Conversion vers un tensor.\n",
    "X_train_tensor = X_train_tensor.unsqueeze(1).float()\n",
    "\n",
    "X_test_tensor = torch.from_numpy(x_test) #Conversion vers un tensor.\n",
    "X_test_tensor = X_test_tensor.unsqueeze(1).float()\n",
    "\n",
    "y_test_tensor = torch.from_numpy(y_test)\n",
    "y_test_tensor = y_test_tensor.long()\n",
    "\n",
    "X_train_tensor.shape, y_test_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#TODO : train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_neuralnet(observation):\n",
    "    #TODO\n",
    "    return prediction\n",
    "\n",
    "test_check_move_the_snake(env, use_neuralnet, simulations=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approche par Renforcement\n",
    "\n",
    "Approcher le problème par renforcement est un défi tout autre. Ici, nous n'apprenons pas à l'I.A. quelle action elle doit séelctionner, elle doit explorer l'environement pour le découvrir.<br><br>\n",
    "\n",
    "### Q Value\n",
    "\n",
    "Nous allons introduire l'idée d'une valeur appelée<b> valeur Q</b>. Celle-ci nous permet d'estimer la valeur d'une action.<br>\n",
    "Si vous considérez le mouvement qui permet d'attraper le fruit, nous savons qu'elle récompense il amène.<br>\n",
    "Assez logiquement, on peut se douter que les actions qui amènent à attraper le fruit vont avoir de fortes valeurs et celles qui s'en éloignent devraient en avoir de plus faible.<br><br>\n",
    "Le réseau va donc associer à votre image (le tableau de jeu), une valeur pour chaque action.<br>\n",
    "- La valeur à suivre est appelée \"Policy Value\". Il s'agit de la plus élevée. En la suivant, on dit que l'on suit la \"policy\" (symbole π). Cette valeur reflète la meilleure action à prendre, d'après le réseau de neurone. On appelle faire cela de l'exploitation : Exploiter les data déjà présentes.\n",
    "- Suivre les autres valeurs, c'est faire de l'exploration. Tenter des choses qui ne sont pas conseillées en espérant trouver de nouvelles stratégies plus intéressantes.<br><br>\n",
    "\n",
    "On peut calculer cette valeur grâce à l'équation de Bellman. L'idée n'est pas que de compter la récompense qui vient, mais de considérer aussi les récompenses à venir si on suit la policy π.<br>\n",
    "Comme on est moins sûr de ce qu'il va arriver dans le futur que dans la prochaine action, on va aussi ajouter un facteur γ aux valeurs à venir.<br><br>\n",
    "<center><b>V(s, a) = R + γ * V(s', a')</b></center>\n",
    "- Où <b>s</b> est l'état, s' l'état suivant s.<br>\n",
    "- Où <b>a</b> est l'action sélectionnée, a' l'action suivante suivant π.<br>\n",
    "- Où <b>R</b> est la récompense immédiate.<br>\n",
    "- Où <b>γ</b> est la valeur de réduction des rewards à venir.<br>\n",
    "- Où <b>V(s', a')</b> est la valeur V de la prochaine étape.<br><br>\n",
    "- Si a est la dernière action, alors V(s, a) = R<br>\n",
    "- La Q value est la valeur V, si l'action a que l'on choisit est toujours l'action prédite par la policy π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO : déterminez quelle est la valeur V0 avec γ = 0.9 si les récompenses à venir sont les suivantes: \n",
    "reward_sequence = [-1,-1,-1,-1,120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO : réitérer le même procéder, si γ = 0.6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La force des réseaux de neurones\n",
    "Comme montré ce matin, les réseaux de neurones sont des approximateurs universels de fonction. Ils sont donc tout à fait appropriés pour trouver quelle est la valeur de V, d'après l'état du jeu.<br>\n",
    "Chaque sortie va représenter une action et sa valeur V."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque #Deque est un outil utile pour avoir un nombre maximum d'éléments dans \n",
    "\n",
    "m_list = deque(maxlen=5)\n",
    "for i in range(7):\n",
    "    m_list.append(i)\n",
    "    \n",
    "print(m_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        \n",
    "        #TODO: Créer votre architecture de réseau.\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #Todo : Faites transiter l'information dans les couches de neurones.\n",
    "        \n",
    "        x = F.relu(x) #Le système doit ressortir une valeur entière pour prédire le résultat\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "net = NeuralNetwork() #Crée l'objet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReinforcementAlgorithm():\n",
    "    def __init__(self, gamma, experience_size, learning_rate, env):\n",
    "        self.gamma = gamma #La valeur de discount.\n",
    "        self.experiences = deque(maxlen=experience_size) #La mémoire de l'I.A. qui va stoquer les expériences.\n",
    "        self.learning_rate = learning_rate #Utilisé pour les réseaux de neurones que nous allons construire.\n",
    "        self.env = env\n",
    "        self.epsilon_start = 0.9\n",
    "        \n",
    "        self.policy_network = #TODO : créez le réseau.\n",
    "        self.target_network = #TODO : créez une copie du réseau.\n",
    "        self.optimizer = #TODO : Paramétrer un optimiseur.\n",
    "        self.epsilon_decay = #Todo : Etablir à a quelle vitesse décroît votre epsilon.\n",
    "        \n",
    "        \n",
    "        self.target_net.load_state_dict(policy_net.state_dict())\n",
    "        self.target_net.eval()\n",
    "        \n",
    "    def learn(self):\n",
    "        #Todo : Optimize le modèle par rapport aux expériences.\n",
    "        pass\n",
    "    \n",
    "    def choose_action(self, state):\n",
    "        #Todo : epsilon greedy\n",
    "        action = 0\n",
    "        return action\n",
    "    \n",
    "    def train(self):\n",
    "        #Todo : Collecte de la data, s'entraine et essaie de résoudre l'environment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
